{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073a2f04-3a01-40f0-b9e5-706cfc1e9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown \n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain import hub\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25799aa3-9c19-447b-b5d0-33d7d1098223",
   "metadata": {},
   "source": [
    "This is a storybook with a purpose of presenting a way of creating a custom RAG(Retrieval-Augmented Generation) framework. The code from this notebook is also present in python files which are used by the llm_app. Here, you can see the thought process of creating the RAG more clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca2218-57d0-4eb9-a456-9b1ec287e24a",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601e373-567e-463c-88bf-f1e064703aa5",
   "metadata": {},
   "source": [
    "I chose the data from the following site: [Blog Corpus](https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus/data). <br>\n",
    "This is a dataset of different blogs written on or before 2004, with each blog being the work of a single user. <br>\n",
    "The dataset originally cotains 681,288 posts, but for the LLM I took only 10000 posts because of computational resource limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab89354-8cf7-465d-9e0c-cc3b6fc53466",
   "metadata": {},
   "source": [
    "I stored this filtered dataset on google drive here: [Blog Corpus Filtered](https://drive.google.com/file/d/1KB6gCv2aTc1DOBF1RoEVhqFHfBL4_ZMn/view?usp=sharing). <br>\n",
    "Now, we can download and extract the data using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a25dc4-7117-406b-b6b7-767c8231881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_data() -> None:\n",
    "    gdown.download('https://drive.google.com/uc?id=1KB6gCv2aTc1DOBF1RoEVhqFHfBL4_ZMn', './data.zip', quiet=False)\n",
    "    with zipfile.ZipFile('./data.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "download_and_extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3f1299-e507-4058-b1f5-fb73ba18855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id gender  age              topic      sign          date  \\\n",
       "0           0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1           1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2           2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3           3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4           4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('blogtext_small.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d90ad5-beae-4959-8c08-4a9feeb21b04",
   "metadata": {},
   "source": [
    "Now, as per RAG model, the data is split into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d356a7-3a8c-4a81-bdcb-352563e1124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_documents(df: pd.DataFrame, chunk_size: int = 128, chunk_overlap: int = 32) -> List[Document]:\n",
    "    loader = DataFrameLoader(df)\n",
    "    data = loader.load()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(data)\n",
    "    return docs\n",
    "\n",
    "docs = load_and_split_documents(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930fe55-b898-4f52-83cd-c1f53ff93c36",
   "metadata": {},
   "source": [
    "With the split data we can load it into our vector database (I chose chromadb). So we need to connect to chromadb docker container, create or get desired collection and fill the collection with out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5b9dfa-4274-47e8-aa3d-5754d103632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set chromadb vectorstore connection variables\n",
    "CHROMADB_HOST = 'host.docker.internal' # chromadb is running as a docker container\n",
    "CHROMADB_PORT = 8000\n",
    "CHROMADB_SETTINGS = Settings(allow_reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16769af-4b43-4d6a-9b5f-6f773300ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init chromadb client and collection\n",
    "client = chromadb.HttpClient(host=CHROMADB_HOST, port=CHROMADB_PORT, settings=CHROMADB_SETTINGS)\n",
    "client.reset()  # resets the database\n",
    "collection = client.get_or_create_collection(\"blog_collection\")\n",
    "\n",
    "# Add the data to the collection\n",
    "for doc in docs:\n",
    "    collection.add(\n",
    "        ids=[str(uuid.uuid1())], metadatas=doc.metadata, documents=doc.page_content\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b4734-bb2d-4bdc-af41-9b1fd70bd889",
   "metadata": {},
   "source": [
    "The data is now set and stored. We can search it whenever we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29f636-f1e4-4d83-8815-c2a473e95ba9",
   "metadata": {},
   "source": [
    "### LLM model response generaton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c9626-ce87-43c9-a666-77e666fd9419",
   "metadata": {},
   "source": [
    "To use an open source huggingface LLM model from the cloud, you need to put your access token.\n",
    "To get an access token you need to go to Hugging Face website and perform the following:\n",
    "\n",
    "    1. Register or Login.\n",
    "    2. Create a User Access or API token in your Hugging Face profile settings.\n",
    "\n",
    "In the profile settings, under Access Tokens, you should see a token hf_xxxxx (old tokens are api_XXXXXXXX or api_org_XXXXXXX). If you do not submit your API token when sending requests to the API, you will not be able to run inference on your private models.\n",
    "\n",
    "When you have the token, run the following cell and enter the token in the input field:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b499b414-2277-4877-94e0-6d6df76273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b4e95-ae66-4c9c-9837-17688588e965",
   "metadata": {},
   "source": [
    "Chromadb is already populated with the documents. Now, we have to connect to the database to access those documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bda5315-a7b5-407c-9ae4-9481c79a12f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id gender  age              topic      sign          date  \\\n",
       "0           0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1           1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2           2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3           3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4           4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data for preview\n",
    "df = pd.read_csv('blogtext_small.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a6d7e-2886-43cb-8ed9-fb350389a89b",
   "metadata": {},
   "source": [
    "Let's take one example from the dataframe and try to examine the LLM performance on information extraction and question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9627b19e-2efe-472d-91fa-3ef6b0b6a792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"             I surf the English news sites a lot looking for tidbits on Korea and how foreigners (like me) view the 'Hermit Kingdom' but also as a way to keep up with this fast-moving place.  Sometimes, though, one needs to check the veracity of the figures put in the papers...especially the local ones.  Here are two examples of how the English version of the Korea Times and that of the JoongAng Ilbo (Daily).  The first is pretty straightforward.   urlLink Korea Times  said that 249 people were arrested for forging Korean passports, but  urlLink JoongAng Ilbo  says just 114 were accused.  Huh?  Another one:  urlLink JoongAng Ilbo  said that S&P is positive on Korean banks (a good thing), while the  urlLink Korea Times  said that S&P was a tad worried about the bad loans that banks extended to small and medium-sized firms.  I have no idea why the simple facts seem to be presented so differently...it can't simply be translation, can it?         \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4dfe90-7e61-48dc-9bd6-9636461daf64",
   "metadata": {},
   "source": [
    "Let's ask the model the following question: How many people did rlLink Korea Times say were arrested for forging Korean passports? <br>\n",
    "From the text we see the answer is 249."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a42d3-dd5d-4336-b9ef-d1264fd54146",
   "metadata": {},
   "source": [
    "If we want the model to understand the question and the documents, we need to initialize embedding function and I chose the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a313f7f-cf32-4dde-88d2-eed207b1e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129de2c9-9438-4a48-ad68-a35de63c658d",
   "metadata": {},
   "source": [
    "Now we can connect to the chromadb, set its embedding function for retrieval and create the retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbcf3311-35d2-4ec6-919f-063287053394",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.HttpClient(host=CHROMADB_HOST, port=CHROMADB_PORT, settings=CHROMADB_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c00e32-6ac9-46d3-8c29-c6681a89881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.HttpClient(host=CHROMADB_HOST, port=CHROMADB_PORT, settings=CHROMADB_SETTINGS)\n",
    "db = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"langchain\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c2583-1c85-42e1-bec0-ae8685f143a0",
   "metadata": {},
   "source": [
    "Before we generate the LLM's output response, let's see if the retriever works. It should return relevant documents for the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317ee163-93a3-41bc-b379-ba769e33e307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Unnamed: 0': 9, 'age': 33, 'date': '09,June,2004', 'gender': 'male', 'id': 3581210, 'sign': 'Aquarius', 'topic': 'InvestmentBanking'}, page_content=\"I surf the English news sites a lot looking for tidbits on Korea and how foreigners (like me) view the 'Hermit Kingdom' but also as a way to keep up with this fast-moving place.  Sometimes, though, one needs to check the veracity of the figures put in the papers...especially the local ones.  Here are two examples of how the English version of the Korea Times and that of the JoongAng Ilbo (Daily).  The first is pretty straightforward.   urlLink Korea Times  said that 249 people were arrested for forging Korean passports, but  urlLink JoongAng Ilbo  says just 114 were accused.  Huh?  Another one:  urlLink JoongAng Ilbo  said that S&P is positive on Korean banks (a good thing), while the  urlLink Korea Times  said that S&P was a tad worried about the bad loans that banks extended to small and medium-sized firms.  I have no idea why the simple facts seem to be presented so differently...it can't simply be translation, can it?\"),\n",
       " Document(metadata={'Unnamed: 0': 30, 'age': 33, 'date': '29,June,2004', 'gender': 'male', 'id': 3581210, 'sign': 'Aquarius', 'topic': 'InvestmentBanking'}, page_content=\"Koreans have a great sense of community.  So much so that sometimes they figure they can have a nap any old place.  Now I understand taking a snooze in a subway car (they are safer here) or taxi (done that a few times), but on some steps?  Well, it happens.   urlLink    I couldn't resist taking a pic of this guy...it was like 6PM and he was already sacked out on the front steps of a building in Sinchon (teen district of Seoul).  Notice his jacket is a step or so down from his resting place.  Must be nice to be in a virtually crime-free city.\"),\n",
       " Document(metadata={'Unnamed: 0': 5470, 'age': 27, 'date': '09,June,2004', 'gender': 'female', 'id': 2821801, 'sign': 'Taurus', 'topic': 'indUnk'}, page_content=\"urlLink North Korea  - Thanks to the IAE, we can shed a little light onto this whole North Korean 'thing'.  /Sarcasm  Another case of 'stating the obvious'.  It'll be interesting to see how/if North Korea comes in line given whats going on in the middle east (Saudi's beginning to crack down on Wahabbism) - heh.\"),\n",
       " Document(metadata={'Unnamed: 0': 5474, 'age': 27, 'date': '09,June,2004', 'gender': 'female', 'id': 2821801, 'sign': 'Taurus', 'topic': 'indUnk'}, page_content='My only response to this whole N. Korean  urlLink situation  is:  NUKE!THEM!FIRST!')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents('How many people did rlLink Korea Times say were arrested for forging Korean passports?', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58a508-d2b8-410c-a140-c5af282f7e52",
   "metadata": {},
   "source": [
    "And it does! We see the first retrieved document is the document we saw earlier (the one on the 9th row in out data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d5744-17b8-4b6b-8d57-638a6437f8cb",
   "metadata": {},
   "source": [
    "Now we can perform model inference. For the inference we need:\n",
    "<ul>\n",
    "    <li> question </li>\n",
    "    <li> context </li>\n",
    "    <li> prompt </li>\n",
    "    <li> LLM model </li>\n",
    "</ul>\n",
    "\n",
    "Question: \"How many people did rlLink Korea Times say were arrested for forging Korean passports?\" <br>\n",
    "Context represents the knowledge from the chromadb, i.e. the retriever. <br>\n",
    "Prompt is the part that combines the question with the context to represent the input to the model. Here we use a popular prompt template which looks like this: <br>\n",
    "<blockquote>\n",
    "\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\"\n",
    "</blockquote> <br>\n",
    "\n",
    "This is a general prompt template which should work good for our example. You can find more about it here: [rlm/rag-prompt](https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=f8b0bb50-1c01-5bf0-864a-1fcba128b633) <br>\n",
    "And for the LLM, we use a Hugging Face model <b> mistralai/Mistral-7B-Instruct-v0.2 </b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3273d012-a0b5-4996-b518-9e37988c4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd719c75-8085-45ed-b88a-cc781a6fa806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\" \n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e972ce-b820-4f79-9a51-ecb72c9cfc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Korea Times reported that 249 people were arrested for forging Korean passports.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"How many people did rlLink Korea Times say were arrested for forging Korean passports?\") # 249 is the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4870b4-372e-41ee-8c7b-ede5c5e9d392",
   "metadata": {},
   "source": [
    "It is also possible to use chat history with the llm. The following code was taken from the [langchain chat history](https://python.langchain.com/v0.1/docs/use_cases/question_answering/chat_history/). <br>\n",
    "Below I use chat history with my example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df1019b6-ec24-4312-897c-4a7480cd82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02d2192-10b5-42ce-bb4f-19d264b7dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dd81cf3-30c8-474d-ae3c-1a7df84593d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: The Korea Times reported that 249 people were arrested for forging Korean passports.\n",
      "\n",
      "Assistant: Yes, 249 people were arrested.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"How many people did rlLink Korea Times say were arrested for forging Korean passports?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "print(ai_msg_1[\"answer\"])\n",
    "\n",
    "second_question = \"Can you just repeat the number?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a21453-dec2-41c6-8ea5-bc69d0d2e29b",
   "metadata": {},
   "source": [
    "We can see he gave the same answer (249) and we asked him a second question which gave no context what was being asked other than referencing the last question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
